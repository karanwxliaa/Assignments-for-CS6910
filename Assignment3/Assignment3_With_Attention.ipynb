{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cvBkd07iYZxG"
      },
      "source": [
        "## 1 Downloading the Dakshina dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iQ5BwqDIYSP8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb==0.12.2 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.12.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (3.1.29)\n",
            "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (5.9.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (2.28.0)\n",
            "Requirement already satisfied: six>=1.13.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (6.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (0.4.0)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (3.5.4)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (1.0.11)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (3.19.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (8.1.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (1.14.0)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (2.3.0)\n",
            "Requirement already satisfied: pathtools in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (0.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (2.3)\n",
            "Requirement already satisfied: configparser>=3.8.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (5.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from wandb==0.12.2) (2.8.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from Click!=8.0.0,>=7.0->wandb==0.12.2) (0.4.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from GitPython>=1.0.0->wandb==0.12.2) (4.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb==0.12.2) (2019.11.28)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb==0.12.2) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb==0.12.2) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.0.0->wandb==0.12.2) (1.26.14)\n",
            "Requirement already satisfied: termcolor<3.0,>=2.2 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from yaspin>=1.0.0->wandb==0.12.2) (2.2.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.12.2) (5.0.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "tar: Error opening archive: Failed to open 'dakshina_dataset_v1.0.tar'\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb==0.12.2\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B3KQEek0Yl0k"
      },
      "source": [
        "## 2 Processing the dataset\n",
        "### 2.1 Data Processing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6wtNj_IqYrW5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "class DataProcessing():\n",
        "\n",
        "    def __init__(self, path, s_lang = 'en', t_lang = \"te\"):\n",
        "    \n",
        "        self.s_lang = s_lang\n",
        "        self.t_lang = t_lang\n",
        "    \n",
        "        self.trainpath = os.path.join(path, t_lang, \"lexicons\", t_lang+\".translit.sampled.train.tsv\")\n",
        "        self.valpath = os.path.join(path, t_lang, \"lexicons\", t_lang+\".translit.sampled.dev.tsv\")\n",
        "        self.testpath = os.path.join(path, t_lang, \"lexicons\", t_lang+\".translit.sampled.test.tsv\")\n",
        "\n",
        "        self.train = pd.read_csv(\n",
        "            self.trainpath,\n",
        "            sep=\"\\t\",\n",
        "            names=[\"tgt\", \"src\", \"count\"],\n",
        "        )\n",
        "        self.test = pd.read_csv(\n",
        "            self.testpath,\n",
        "            sep=\"\\t\",\n",
        "            names=[\"tgt\", \"src\", \"count\"],\n",
        "        )\n",
        "        self.val = pd.read_csv(\n",
        "            self.valpath,\n",
        "            sep=\"\\t\",\n",
        "            names=[\"tgt\", \"src\", \"count\"],\n",
        "        )\n",
        "\n",
        "        #Train Data\n",
        "        self.train_data = self.preprocess(self.train[\"src\"].to_list(), self.train[\"tgt\"].to_list())\n",
        "        (\n",
        "            self.train_encoder_input,\n",
        "            self.train_decoder_input,\n",
        "            self.train_decoder_target,\n",
        "            self.source_voccab,\n",
        "            self.target_voccab,\n",
        "        ) = self.train_data\n",
        "\n",
        "        #character to integer and integer to character\n",
        "        self.src_charTOint, self.src_intTOchar = self.source_voccab\n",
        "        self.tar_charTOint, self.tar_intTOchar = self.target_voccab\n",
        "\n",
        "        #Validation Data\n",
        "        self.val_data = self.encode(\n",
        "            self.val[\"src\"].to_list(),\n",
        "            self.val[\"tgt\"].to_list(),\n",
        "            list(self.src_charTOint.keys()),\n",
        "            list(self.tar_charTOint.keys()),\n",
        "            src_charTOint=self.src_charTOint,\n",
        "            tar_charTOint=self.tar_charTOint,\n",
        "        )\n",
        "        self.val_encoder_input, self.val_decoder_input, self.val_decoder_target = self.val_data\n",
        "        self.src_charTOint, self.src_intTOchar = self.source_voccab\n",
        "        self.tar_charTOint, self.tar_intTOchar = self.target_voccab\n",
        "\n",
        "        #Test Data\n",
        "        self.test_data = self.encode(\n",
        "            self.test[\"src\"].to_list(),\n",
        "            self.test[\"tgt\"].to_list(),\n",
        "            list(self.src_charTOint.keys()),\n",
        "            list(self.tar_charTOint.keys()),\n",
        "            src_charTOint=self.src_charTOint,\n",
        "            tar_charTOint=self.tar_charTOint,\n",
        "        )\n",
        "        self.test_encoder_input, self.test_decoder_input, self.test_decoder_target = self.test_data\n",
        "        self.src_charTOint, self.src_intTOchar = self.source_voccab\n",
        "        self.tar_charTOint, self.tar_intTOchar = self.target_voccab\n",
        "\n",
        "\n",
        "    def dictionary_lookup(self, voccab):\n",
        "        charTOint = dict([(char, i) for i, char in enumerate(voccab)])\n",
        "        intTOchar = dict((i, char) for char, i in charTOint.items())\n",
        "        return charTOint, intTOchar\n",
        "\n",
        "    def preprocess(self, source , target):\n",
        "        source_chars = set()\n",
        "        target_chars = set()\n",
        "\n",
        "        source = [str(x) for x in source]\n",
        "        target = [str(x) for x in target]\n",
        "\n",
        "        source_words,target_words = [],[]\n",
        "        for src, tgt in zip(source, target):\n",
        "            tgt = \"\\t\" + tgt + \"\\n\"\n",
        "            \n",
        "            source_words.append(src)\n",
        "            target_words.append(tgt)\n",
        "\n",
        "            for char in src:\n",
        "                if char not in source_chars:\n",
        "                    source_chars.add(char)\n",
        "\n",
        "            for char in tgt:\n",
        "                if char not in target_chars:\n",
        "                    target_chars.add(char)\n",
        "\n",
        "        source_chars = sorted(list(source_chars))\n",
        "        target_chars = sorted(list(target_chars))\n",
        "\n",
        "        #Add space\n",
        "        source_chars.append(\" \")\n",
        "        target_chars.append(\" \")\n",
        "\n",
        "        num_encoder_tokens = len(source_chars)\n",
        "        num_decoder_tokens = len(target_chars)\n",
        "        max_source_length = max([len(txt) for txt in source_words])\n",
        "        max_target_length = max([len(txt) for txt in target_words])\n",
        "\n",
        "        print(\"No. of samples:\", len(source))\n",
        "        print(\"Src voccab length:\", num_encoder_tokens)\n",
        "        print(\"Tar voccab length:\", num_decoder_tokens)\n",
        "        print(\"Max iput sequence length:\", max_source_length)\n",
        "        print(\"Max output sequence length:\", max_target_length)\n",
        "\n",
        "        return self.encode(source_words, target_words, source_chars, target_chars)\n",
        "    \n",
        "    def encode(self, source, target, source_chars, target_chars, src_charTOint=None, tar_charTOint=None):\n",
        "        num_decoder_tokens = len(target_chars)\n",
        "        num_encoder_tokens = len(source_chars)\n",
        "        max_source_length = max([len(txt) for txt in source])\n",
        "        max_target_length = max([len(txt) for txt in target])\n",
        "\n",
        "        source_voccab, target_voccab = None, None\n",
        "        if src_charTOint == None and tar_charTOint == None:\n",
        "\n",
        "            print(\"Dictionary lookups for char to int mapping and vice versa\")\n",
        "            src_charTOint, src_intTOchar = self.dictionary_lookup(source_chars)\n",
        "            tar_charTOint, tar_intTOchar = self.dictionary_lookup(target_chars)\n",
        "\n",
        "            source_voccab = (src_charTOint, src_intTOchar)\n",
        "            target_voccab = (tar_charTOint, tar_intTOchar)\n",
        "\n",
        "        encoder_input_data = np.zeros(\n",
        "            (len(source), max_source_length, num_encoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "        decoder_input_data = np.zeros(\n",
        "            (len(source), max_target_length, num_decoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "        decoder_target_data = np.zeros(\n",
        "            (len(source), max_target_length, num_decoder_tokens), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        for i, (input_text, target_text) in enumerate(zip(source, target)):\n",
        "            for t, char in enumerate(input_text):\n",
        "                encoder_input_data[i, t, src_charTOint[char]] = 1.0\n",
        "            encoder_input_data[i, t + 1 :, src_charTOint[\" \"]] = 1.0\n",
        "            for t, char in enumerate(target_text):\n",
        "                \n",
        "                decoder_input_data[i, t, tar_charTOint[char]] = 1.0\n",
        "                if t > 0:\n",
        "                    decoder_target_data[i, t - 1, tar_charTOint[char]] = 1.0\n",
        "\n",
        "            decoder_input_data[i, t + 1 :, tar_charTOint[\" \"]] = 1.0\n",
        "            decoder_target_data[i, t:, tar_charTOint[\" \"]] = 1.0\n",
        "\n",
        "        if source_voccab != None and target_voccab != None:\n",
        "            return (\n",
        "                encoder_input_data,\n",
        "                decoder_input_data,\n",
        "                decoder_target_data,\n",
        "                source_voccab,\n",
        "                target_voccab,\n",
        "            )\n",
        "        else:\n",
        "\n",
        "            return encoder_input_data, decoder_input_data, decoder_target_data\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JYb2pXHTZKc0"
      },
      "source": [
        "### 2.2 Processing the database\n",
        "\n",
        "(input language = English and output language = Telugu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F-kjn6OdZVkz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of samples: 58550\n",
            "Src voccab length: 27\n",
            "Tar voccab length: 66\n",
            "Max iput sequence length: 25\n",
            "Max output sequence length: 22\n",
            "Dictionary lookups for char to int mapping and vice versa\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "DATAPATH = r\"dakshina_dataset_v1.0\"\n",
        "\n",
        "dataBase = DataProcessing(DATAPATH) \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lKyABHLuZqGx"
      },
      "source": [
        "## 3 RNNs model for sequence to sequence machine translation \n",
        "### 3.1 Seq2Seq *Attention* Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "34A-m6mWROb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.8 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.14.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.16.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (4.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (3.19.4)\n",
            "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.12)\n",
            "Requirement already satisfied: setuptools in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (63.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (0.26.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow==2.8) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.28.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\karan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CXcjvZ5x9Gdi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \n",
        "    #Bahdanau attention\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),initializer='uniform',trainable=True)\n",
        "\n",
        "        self.U_a = self.add_weight(name='U_a',shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),initializer='uniform',trainable=True)\n",
        "        \n",
        "        self.V_a = self.add_weight(name='V_a',shape=tf.TensorShape((input_shape[0][2], 1)),initializer='uniform',trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  \n",
        "\n",
        "    def call(self, inp, verbose=False):\n",
        "        # [encoder_output_sequence, decoder_output_sequence]\n",
        "        \n",
        "        assert type(inp) == list\n",
        "        enc_out_seq, dec_out_seq = inp\n",
        "        \n",
        "        if verbose:\n",
        "            print('encoder_out-', enc_out_seq.shape)\n",
        "            print('decoder_out-', dec_out_seq.shape)\n",
        "\n",
        "        def energy_step(inp, states):\n",
        "            #step fn\n",
        "            assert_msg = \"The tates must be an iterable but got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "           #shaping tensor\n",
        "            en_seq_len, en_hidden = enc_out_seq.shape[1], enc_out_seq.shape[2]\n",
        "            de_hidden = inp.shape[-1]\n",
        "\n",
        "            W_a_dot_s = K.dot(enc_out_seq, self.W_a)\n",
        "\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inp, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inp, states):\n",
        "            #step function\n",
        "\n",
        "            assert_msg = \"The states have to be an iterable but got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            c_i = K.sum(enc_out_seq * K.expand_dims(inp, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(enc_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(enc_out_seq, axis=2)  \n",
        "\n",
        "        last_out, e_out, _ = K.rnn(\n",
        "            energy_step, dec_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        #Context vec\n",
        "        last_out, c_out, _ = K.rnn(\n",
        "            context_step, e_out, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_out, e_out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7qHr8zEN9HEH"
      },
      "source": [
        "### 3.1 Seq2Seq translation Model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AT83-HQ3Z5fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaranwxlia\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed, Concatenate\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model, Sequential,  Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "class S2STranslation():\n",
        "\n",
        "    def __init__(self, ModConfigDict, srcCharTOInt, tgtCharTOInt, using_pretrained_model = False):\n",
        "        self.cell_type = ModConfigDict[\"cell_type\"]\n",
        "        self.numEncoders = ModConfigDict[\"numEncoders\"]\n",
        "        self.latentDim = ModConfigDict[\"latentDim\"]\n",
        "        self.numDecoders = ModConfigDict[\"numDecoders\"]\n",
        "        self.hidden = ModConfigDict[\"hidden\"]\n",
        "        self.dropout = ModConfigDict[\"dropout\"]\n",
        "       \n",
        "        self.tgtCharTOInt = tgtCharTOInt\n",
        "        self.srcCharTOInt = srcCharTOInt\n",
        "\n",
        "    def build_configurable_model(self):  \n",
        "\n",
        "        #RNN     \n",
        "        if self.cell_type == \"RNN\":\n",
        "\n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state = encoder(encoder_inp)\n",
        "            encoder_state = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_out, _ = decoder(decoder_inp, initial_state=encoder_state)\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_out = hidden(decoder_out)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        #LSTM\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "\n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state_h, state_c = encoder(encoder_out)\n",
        "            encoder_state = [state_h, state_c]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_out, _, _ = decoder(\n",
        "                    decoder_out, initial_state=encoder_state\n",
        "                )\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_out = hidden(decoder_out)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model\n",
        "\n",
        "        #GRU\n",
        "        elif self.cell_type == \"GRU\":\n",
        "\n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state = encoder(encoder_inp)\n",
        "            encoder_state = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_out, _ = decoder(decoder_inp, initial_state=encoder_state)\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_out = hidden(decoder_out)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model\n",
        "\n",
        "\n",
        "            \n",
        "    def build_attention_model(self):\n",
        "\n",
        "        #RNN       \n",
        "        if self.cell_type == \"RNN\":\n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state = encoder(encoder_inp) \n",
        "                \n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_out                  \n",
        "            encoder_state = [state]\n",
        "            \n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = SimpleRNN(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "\n",
        "                decoder_out, _ = decoder(decoder_inp, initial_state=encoder_state)\n",
        "                \n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_out\n",
        "\n",
        "            attention_layer = AttentionLayer(name='attention_layer')\n",
        "            attention_out, attention_st = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_out = hidden(decoder_concat_input)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        #LSTM\n",
        "        elif self.cell_type == \"LSTM\":\n",
        "            \n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state_h, state_c = encoder(encoder_out)\n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_out                  \n",
        "         \n",
        "            encoder_state = [state_h, state_c]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = LSTM(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_out, _, _ = decoder(\n",
        "                    decoder_out, initial_state=encoder_state\n",
        "                )\n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_out\n",
        "\n",
        "            attention_layer = AttentionLayer(name='attention_layer')\n",
        "            attention_out, attention_st = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_out = hidden(decoder_concat_input)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model\n",
        "        \n",
        "        #GRU\n",
        "        elif self.cell_type == \"GRU\":\n",
        "\n",
        "            # encoder\n",
        "            encoder_inp = Input(shape=(None, len(self.srcCharTOInt)))\n",
        "            encoder_out = encoder_inp\n",
        "\n",
        "            for i in range(1, self.numEncoders + 1):\n",
        "                encoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_state=True,\n",
        "                    return_sequences=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                encoder_out, state = encoder(encoder_inp)\n",
        "\n",
        "                if i == 1:\n",
        "                    encoder_first_outputs= encoder_out                  \n",
        "         \n",
        "            encoder_state = [state]\n",
        "\n",
        "            # decoder\n",
        "            decoder_inp = Input(shape=(None, len(self.tgtCharTOInt)))\n",
        "            decoder_out = decoder_inp\n",
        "\n",
        "            for i in range(1, self.numDecoders + 1):\n",
        "                decoder = GRU(\n",
        "                    self.latentDim,\n",
        "                    return_sequences=True,\n",
        "                    return_state=True,\n",
        "                    dropout=self.dropout,\n",
        "                )\n",
        "                decoder_out, _ = decoder(decoder_inp, initial_state=encoder_state)\n",
        "                if i == self.numDecoders:\n",
        "                    decoder_first_outputs = decoder_out\n",
        "\n",
        "            attention_layer = AttentionLayer(name='attention_layer')\n",
        "            attention_out, attention_st = attention_layer([encoder_first_outputs, decoder_first_outputs])\n",
        "\n",
        "            decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attention_out])\n",
        "\n",
        "            # dense\n",
        "            hidden = Dense(self.hidden, activation=\"relu\")\n",
        "            hidden_time = TimeDistributed(hidden, name='time_distributed_layer')\n",
        "            hidden_out = hidden(decoder_concat_input)\n",
        "            dec_dense = Dense(len(self.tgtCharTOInt), activation=\"softmax\")\n",
        "            decoder_out = dec_dense(hidden_out)\n",
        "            model = Model([encoder_inp, decoder_inp], decoder_out)\n",
        "            \n",
        "            return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KjLa_0loaBPT"
      },
      "source": [
        "### 3.2 Training the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F-B1RkORaHjO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import RNN, LSTM, GRU, Dense\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "#using a gpu\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "def train():\n",
        "    default_config = {\n",
        "        \"cell_type\": \"RNN\",\n",
        "        \"latentDim\": 256,\n",
        "        \"hidden\": 128,\n",
        "        \"optimiser\": \"rmsprop\",\n",
        "        \"numEncoders\": 1,\n",
        "        \"numDecoders\": 1,\n",
        "        \"dropout\": 0.2,\n",
        "        \"epochs\": 1,\n",
        "        \"batch_size\": 64,\n",
        "    }\n",
        "\n",
        "    wandb.init(config=default_config)\n",
        "    #wandb.init(config=default_config,  project=\"Assignment-3_WithAttention\", entity=\"karanwxlia\")\n",
        "    config = wandb.config\n",
        "    \n",
        "    wandb.run.name = (\n",
        "        str(config.cell_type)\n",
        "        + dataBase.source_lang\n",
        "        + str(config.numEncoders)\n",
        "        + \"_\"\n",
        "        + dataBase.target_lang\n",
        "        + \"_\"\n",
        "        + str(config.numDecoders)\n",
        "        + \"_\"\n",
        "        + config.optimiser\n",
        "        + \"_\"\n",
        "        + str(config.epochs)\n",
        "        + \"_\"\n",
        "        + str(config.dropout) \n",
        "        + \"_\"\n",
        "        + str(config.batch_size)\n",
        "        + \"_\"\n",
        "        + str(config.latentDim)\n",
        "    )\n",
        "    wandb.run.save()\n",
        "\n",
        "    modelInit = S2STranslation(config,srcChar2Int=dataBase.src_charTOint, tgtChar2Int=dataBase.tar_charTOint)\n",
        "    \n",
        "    model = modelInit.build_attention_model()\n",
        "    model.summary()\n",
        "    model.compile(\n",
        "        optimizer=config.optimiser,\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    earlystopping = EarlyStopping(\n",
        "        monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\"\n",
        "    )\n",
        "    model.fit(\n",
        "        [dataBase.train_encoder_input, dataBase.train_decoder_input],\n",
        "        dataBase.train_decoder_target,\n",
        "        batch_size=config.batch_size,\n",
        "        epochs=config.epochs,\n",
        "        validation_data=([dataBase.val_encoder_input, dataBase.val_decoder_input], dataBase.val_decoder_target),\n",
        "        callbacks=[earlystopping, WandbCallback()],\n",
        "    )\n",
        "\n",
        "    model.save(os.path.join(\"./TrainedAttentionModels\", wandb.run.name))    \n",
        "    wandb.finish()\n",
        "    \n",
        "    #return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwIBB2t3ahQK"
      },
      "source": [
        "Running the wandb sweep: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hbZXjvV9agMF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: q6wtpkdx\n",
            "Sweep URL: https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 49rva5iy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaranwxlia\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">blooming-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/49rva5iy\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/49rva5iy</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_233732-49rva5iy</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn_2 (SimpleRNN)       [(None, None, 64),   5888        ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " simple_rnn_5 (SimpleRNN)       [(None, None, 64),   8384        ['input_2[0][0]',                \n",
            "                                 (None, 64)]                      'simple_rnn_2[0][1]']           \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, None, 64),   5888        ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 64),  8256        ['simple_rnn[0][0]',             \n",
            " r)                              (None, None, None)               'simple_rnn_5[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 128)    0           ['simple_rnn_5[0][0]',           \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 32)     4128        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     2178        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,722\n",
            "Trainable params: 34,722\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "1830/1830 [==============================] - 42s 21ms/step - loss: 0.9802 - accuracy: 0.7347 - val_loss: 1.2458 - val_accuracy: 0.7529\n",
            "Epoch 2/20\n",
            "1830/1830 [==============================] - 43s 23ms/step - loss: 0.5793 - accuracy: 0.8359 - val_loss: 1.2404 - val_accuracy: 0.7834\n",
            "Epoch 3/20\n",
            "1830/1830 [==============================] - 42s 23ms/step - loss: 0.4653 - accuracy: 0.8667 - val_loss: 1.2857 - val_accuracy: 0.7885\n",
            "Epoch 4/20\n",
            "1830/1830 [==============================] - 42s 23ms/step - loss: 0.4139 - accuracy: 0.8799 - val_loss: 1.1303 - val_accuracy: 0.8125\n",
            "Epoch 5/20\n",
            "1830/1830 [==============================] - 40s 22ms/step - loss: 0.3846 - accuracy: 0.8879 - val_loss: 1.2753 - val_accuracy: 0.7918\n",
            "Epoch 6/20\n",
            "1830/1830 [==============================] - 45s 24ms/step - loss: 0.3665 - accuracy: 0.8929 - val_loss: 1.3707 - val_accuracy: 0.7779\n",
            "Epoch 7/20\n",
            "1830/1830 [==============================] - 45s 24ms/step - loss: 0.3560 - accuracy: 0.8954 - val_loss: 1.0994 - val_accuracy: 0.8265\n",
            "Epoch 8/20\n",
            "1830/1830 [==============================] - 37s 20ms/step - loss: 0.3472 - accuracy: 0.8979 - val_loss: 1.2571 - val_accuracy: 0.8029\n",
            "Epoch 9/20\n",
            "1830/1830 [==============================] - 41s 22ms/step - loss: 0.3380 - accuracy: 0.9003 - val_loss: 1.1372 - val_accuracy: 0.8314\n",
            "Epoch 10/20\n",
            "1830/1830 [==============================] - 40s 22ms/step - loss: 0.3327 - accuracy: 0.9020 - val_loss: 1.1163 - val_accuracy: 0.8340\n",
            "Epoch 11/20\n",
            "1830/1830 [==============================] - 47s 26ms/step - loss: 0.3283 - accuracy: 0.9030 - val_loss: 1.0864 - val_accuracy: 0.8355\n",
            "Epoch 12/20\n",
            "1830/1830 [==============================] - 46s 25ms/step - loss: 0.3238 - accuracy: 0.9043 - val_loss: 1.1345 - val_accuracy: 0.8297\n",
            "Epoch 12: early stopping\n",
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\RNNen3_te_3_rmsprop_20_0.2_32_64\\assets\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 28020<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_233732-49rva5iy\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_233732-49rva5iy\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.90426</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>1.0864</td></tr><tr><td>epoch</td><td>11</td></tr><tr><td>loss</td><td>0.32383</td></tr><tr><td>val_accuracy</td><td>0.82967</td></tr><tr><td>val_loss</td><td>1.13446</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">blooming-sweep-1</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/49rva5iy\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/49rva5iy</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i94dt723 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">noble-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/i94dt723\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/i94dt723</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_234630-i94dt723</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, None, 64),   17856       ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, None, 64),   25344       ['input_2[0][0]',                \n",
            "                                 (None, 64)]                      'gru_1[0][1]']                  \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, None, 64),   17856       ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 64),  8256        ['gru[0][0]',                    \n",
            " r)                              (None, None, None)               'gru_3[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 128)    0           ['gru_3[0][0]',                  \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 16)     2064        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     1122        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 72,498\n",
            "Trainable params: 72,498\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "915/915 [==============================] - 45s 44ms/step - loss: 1.2288 - accuracy: 0.6793 - val_loss: 1.3399 - val_accuracy: 0.6986\n",
            "Epoch 2/10\n",
            "915/915 [==============================] - 49s 54ms/step - loss: 0.9381 - accuracy: 0.7375 - val_loss: 1.4471 - val_accuracy: 0.7116\n",
            "Epoch 3/10\n",
            "915/915 [==============================] - 42s 46ms/step - loss: 0.8271 - accuracy: 0.7646 - val_loss: 1.4394 - val_accuracy: 0.7252\n",
            "Epoch 4/10\n",
            "915/915 [==============================] - 44s 48ms/step - loss: 0.6826 - accuracy: 0.8034 - val_loss: 1.4370 - val_accuracy: 0.7458\n",
            "Epoch 5/10\n",
            "915/915 [==============================] - 46s 50ms/step - loss: 0.4839 - accuracy: 0.8606 - val_loss: 1.6993 - val_accuracy: 0.7385\n",
            "Epoch 6/10\n",
            "915/915 [==============================] - 47s 51ms/step - loss: 0.3759 - accuracy: 0.8928 - val_loss: 1.9770 - val_accuracy: 0.7178\n",
            "Epoch 7/10\n",
            "915/915 [==============================] - 54s 59ms/step - loss: 0.3219 - accuracy: 0.9070 - val_loss: 1.5039 - val_accuracy: 0.7936\n",
            "Epoch 8/10\n",
            "915/915 [==============================] - 44s 48ms/step - loss: 0.2905 - accuracy: 0.9153 - val_loss: 1.5235 - val_accuracy: 0.8001\n",
            "Epoch 9/10\n",
            "915/915 [==============================] - 40s 43ms/step - loss: 0.2694 - accuracy: 0.9208 - val_loss: 1.6623 - val_accuracy: 0.7881\n",
            "Epoch 10/10\n",
            "915/915 [==============================] - 39s 43ms/step - loss: 0.2549 - accuracy: 0.9246 - val_loss: 1.6179 - val_accuracy: 0.8044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen2_te_2_rmsprop_10_0.1_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen2_te_2_rmsprop_10_0.1_64_64\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E72758E950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E729E21CC0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E720AAC790> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 19224<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_234630-i94dt723\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_234630-i94dt723\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.92457</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.3399</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.25492</td></tr><tr><td>val_accuracy</td><td>0.80444</td></tr><tr><td>val_loss</td><td>1.61788</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">noble-sweep-2</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/i94dt723\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/i94dt723</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vkl73je3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">dainty-sweep-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/vkl73je3\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/vkl73je3</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_235421-vkl73je3</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 256),  290816      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  330752      ['input_2[0][0]',                \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 256),  131328     ['lstm[0][0]',                   \n",
            " r)                              (None, None, None)               'lstm_1[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 512)    0           ['lstm_1[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 16)     8208        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     1122        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 762,226\n",
            "Trainable params: 762,226\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1830/1830 [==============================] - 238s 127ms/step - loss: 0.9832 - accuracy: 0.7382 - val_loss: 1.3272 - val_accuracy: 0.7684\n",
            "Epoch 2/10\n",
            "1830/1830 [==============================] - 251s 137ms/step - loss: 0.3498 - accuracy: 0.9016 - val_loss: 1.4314 - val_accuracy: 0.7989\n",
            "Epoch 3/10\n",
            "1830/1830 [==============================] - 226s 124ms/step - loss: 0.2585 - accuracy: 0.9251 - val_loss: 1.5941 - val_accuracy: 0.7930\n",
            "Epoch 4/10\n",
            "1830/1830 [==============================] - 221s 121ms/step - loss: 0.2265 - accuracy: 0.9335 - val_loss: 1.7937 - val_accuracy: 0.7777\n",
            "Epoch 5/10\n",
            "1830/1830 [==============================] - 207s 113ms/step - loss: 0.2067 - accuracy: 0.9391 - val_loss: 1.7280 - val_accuracy: 0.8047\n",
            "Epoch 6/10\n",
            "1830/1830 [==============================] - 203s 111ms/step - loss: 0.1937 - accuracy: 0.9427 - val_loss: 1.8004 - val_accuracy: 0.7991\n",
            "Epoch 7/10\n",
            "1830/1830 [==============================] - 201s 110ms/step - loss: 0.1817 - accuracy: 0.9462 - val_loss: 1.7284 - val_accuracy: 0.8061\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\LSTMen1_te_1_adam_10_0.1_32_256\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\LSTMen1_te_1_adam_10_0.1_32_256\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E71E5938E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E72DAB3BE0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 20364<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_235421-vkl73je3\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230128_235421-vkl73je3\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.94619</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.32723</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.18166</td></tr><tr><td>val_accuracy</td><td>0.80607</td></tr><tr><td>val_loss</td><td>1.72839</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">dainty-sweep-3</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/vkl73je3\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/vkl73je3</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9wdy2txc with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">vital-sweep-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/9wdy2txc\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/9wdy2txc</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002029-9wdy2txc</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, None, 32),   7680        ['input_1[0][0]']                \n",
            "                                 (None, 32),                                                      \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 32),   8320        ['lstm[0][0]']                   \n",
            "                                 (None, 32),                                                      \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, None, 32),   8320        ['lstm_1[0][0]']                 \n",
            "                                 (None, 32),                                                      \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 32),   12672       ['input_2[0][0]',                \n",
            "                                 (None, 32),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 32)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, None, 32),   8320        ['lstm_3[0][0]',                 \n",
            "                                 (None, 32),                      'lstm_2[0][1]',                 \n",
            "                                 (None, 32)]                      'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 32),  2080        ['lstm[0][0]',                   \n",
            " r)                              (None, None, None)               'lstm_4[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 64)     0           ['lstm_4[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 32)     2080        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     2178        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 51,650\n",
            "Trainable params: 51,650\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "915/915 [==============================] - 48s 45ms/step - loss: 1.3401 - accuracy: 0.6449 - val_loss: 1.5690 - val_accuracy: 0.6558\n",
            "Epoch 2/20\n",
            "915/915 [==============================] - 43s 47ms/step - loss: 1.0638 - accuracy: 0.7038 - val_loss: 1.5256 - val_accuracy: 0.6961\n",
            "Epoch 3/20\n",
            "915/915 [==============================] - 44s 49ms/step - loss: 0.9748 - accuracy: 0.7258 - val_loss: 1.5126 - val_accuracy: 0.7133\n",
            "Epoch 4/20\n",
            "915/915 [==============================] - 36s 39ms/step - loss: 0.9101 - accuracy: 0.7429 - val_loss: 1.5588 - val_accuracy: 0.7159\n",
            "Epoch 5/20\n",
            "915/915 [==============================] - 36s 39ms/step - loss: 0.8577 - accuracy: 0.7568 - val_loss: 1.5360 - val_accuracy: 0.7236\n",
            "Epoch 6/20\n",
            "915/915 [==============================] - 38s 41ms/step - loss: 0.8183 - accuracy: 0.7668 - val_loss: 1.6576 - val_accuracy: 0.7155\n",
            "Epoch 7/20\n",
            "915/915 [==============================] - 37s 40ms/step - loss: 0.7889 - accuracy: 0.7742 - val_loss: 1.6885 - val_accuracy: 0.7157\n",
            "Epoch 8/20\n",
            "915/915 [==============================] - 44s 48ms/step - loss: 0.7667 - accuracy: 0.7803 - val_loss: 1.6671 - val_accuracy: 0.7199\n",
            "Epoch 9/20\n",
            "915/915 [==============================] - 38s 42ms/step - loss: 0.7460 - accuracy: 0.7855 - val_loss: 1.6221 - val_accuracy: 0.7243\n",
            "Epoch 10/20\n",
            "915/915 [==============================] - 36s 40ms/step - loss: 0.7295 - accuracy: 0.7900 - val_loss: 1.7179 - val_accuracy: 0.7219\n",
            "Epoch 10: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\LSTMen3_te_2_rmsprop_20_0.3_64_32\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\LSTMen3_te_2_rmsprop_20_0.3_64_32\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E72CB7AD70> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E73E0A4550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E725FE0DF0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E7279C5C90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E71E443D00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 10404<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002029-9wdy2txc\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002029-9wdy2txc\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.79005</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>1.51263</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.72949</td></tr><tr><td>val_accuracy</td><td>0.72187</td></tr><tr><td>val_loss</td><td>1.71786</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">vital-sweep-4</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/9wdy2txc\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/9wdy2txc</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tksszgd4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">stellar-sweep-5</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/tksszgd4\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/tksszgd4</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002736-tksszgd4</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 128),  60288       ['input_1[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, None, 128),  75264       ['input_2[0][0]',                \n",
            "                                 (None, 128)]                     'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, None, 128),  60288       ['input_1[0][0]']                \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 128),  32896      ['gru[0][0]',                    \n",
            " r)                              (None, None, None)               'gru_3[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 256)    0           ['gru_3[0][0]',                  \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 128)    32896       ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     8514        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 270,146\n",
            "Trainable params: 270,146\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "1830/1830 [==============================] - 110s 57ms/step - loss: 0.8690 - accuracy: 0.7592 - val_loss: 1.4486 - val_accuracy: 0.7620\n",
            "Epoch 2/20\n",
            "1830/1830 [==============================] - 108s 59ms/step - loss: 0.5031 - accuracy: 0.8523 - val_loss: 1.4985 - val_accuracy: 0.7714\n",
            "Epoch 3/20\n",
            "1830/1830 [==============================] - 114s 62ms/step - loss: 0.4200 - accuracy: 0.8748 - val_loss: 1.6727 - val_accuracy: 0.7487\n",
            "Epoch 4/20\n",
            "1830/1830 [==============================] - 109s 60ms/step - loss: 0.3800 - accuracy: 0.8861 - val_loss: 1.4503 - val_accuracy: 0.7957\n",
            "Epoch 5/20\n",
            "1830/1830 [==============================] - 113s 62ms/step - loss: 0.3522 - accuracy: 0.8941 - val_loss: 1.5587 - val_accuracy: 0.7884\n",
            "Epoch 6/20\n",
            "1830/1830 [==============================] - 112s 61ms/step - loss: 0.3328 - accuracy: 0.8998 - val_loss: 1.6029 - val_accuracy: 0.7880\n",
            "Epoch 7/20\n",
            "1830/1830 [==============================] - 110s 60ms/step - loss: 0.3182 - accuracy: 0.9036 - val_loss: 1.6499 - val_accuracy: 0.7893\n",
            "Epoch 8/20\n",
            "1830/1830 [==============================] - 111s 60ms/step - loss: 0.3061 - accuracy: 0.9073 - val_loss: 1.6769 - val_accuracy: 0.7808\n",
            "Epoch 9/20\n",
            "1830/1830 [==============================] - 110s 60ms/step - loss: 0.2963 - accuracy: 0.9099 - val_loss: 1.7492 - val_accuracy: 0.7846\n",
            "Epoch 9: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_1_rmsprop_20_0.3_32_128\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_1_rmsprop_20_0.3_32_128\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E71FD4BA60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E74040F9D0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E72FDA0400> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 14560<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002736-tksszgd4\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_002736-tksszgd4\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.90994</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.44864</td></tr><tr><td>epoch</td><td>8</td></tr><tr><td>loss</td><td>0.29632</td></tr><tr><td>val_accuracy</td><td>0.78459</td></tr><tr><td>val_loss</td><td>1.74924</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">stellar-sweep-5</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/tksszgd4\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/tksszgd4</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a13yjr8g with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fluent-sweep-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/a13yjr8g\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/a13yjr8g</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_004434-a13yjr8g</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " simple_rnn_2 (SimpleRNN)       [(None, None, 32),   1920        ['input_1[0][0]']                \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " simple_rnn_5 (SimpleRNN)       [(None, None, 32),   3168        ['input_2[0][0]',                \n",
            "                                 (None, 32)]                      'simple_rnn_2[0][1]']           \n",
            "                                                                                                  \n",
            " simple_rnn (SimpleRNN)         [(None, None, 32),   1920        ['input_1[0][0]']                \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 32),  2080        ['simple_rnn[0][0]',             \n",
            " r)                              (None, None, None)               'simple_rnn_5[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 64)     0           ['simple_rnn_5[0][0]',           \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 16)     1040        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     1122        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,250\n",
            "Trainable params: 11,250\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "1830/1830 [==============================] - 32s 16ms/step - loss: 1.2048 - accuracy: 0.6807 - val_loss: 1.5559 - val_accuracy: 0.6884\n",
            "Epoch 2/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.8807 - accuracy: 0.7563 - val_loss: 1.4899 - val_accuracy: 0.7148\n",
            "Epoch 3/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.7069 - accuracy: 0.8022 - val_loss: 1.4667 - val_accuracy: 0.7284\n",
            "Epoch 4/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.6500 - accuracy: 0.8160 - val_loss: 1.5658 - val_accuracy: 0.7290\n",
            "Epoch 5/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.6179 - accuracy: 0.8243 - val_loss: 1.5028 - val_accuracy: 0.7384\n",
            "Epoch 6/20\n",
            "1830/1830 [==============================] - 29s 16ms/step - loss: 0.5987 - accuracy: 0.8290 - val_loss: 1.2868 - val_accuracy: 0.7852\n",
            "Epoch 7/20\n",
            "1830/1830 [==============================] - 33s 18ms/step - loss: 0.5841 - accuracy: 0.8330 - val_loss: 1.2298 - val_accuracy: 0.7927\n",
            "Epoch 8/20\n",
            "1830/1830 [==============================] - 30s 17ms/step - loss: 0.5729 - accuracy: 0.8358 - val_loss: 1.5070 - val_accuracy: 0.7568\n",
            "Epoch 9/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.5640 - accuracy: 0.8380 - val_loss: 1.3076 - val_accuracy: 0.7880\n",
            "Epoch 10/20\n",
            "1830/1830 [==============================] - 27s 15ms/step - loss: 0.5558 - accuracy: 0.8399 - val_loss: 1.4680 - val_accuracy: 0.7708\n",
            "Epoch 11/20\n",
            "1830/1830 [==============================] - 25s 14ms/step - loss: 0.5504 - accuracy: 0.8416 - val_loss: 1.2603 - val_accuracy: 0.8042\n",
            "Epoch 12/20\n",
            "1830/1830 [==============================] - 24s 13ms/step - loss: 0.5445 - accuracy: 0.8432 - val_loss: 1.3699 - val_accuracy: 0.7893\n",
            "Epoch 13/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.5398 - accuracy: 0.8445 - val_loss: 1.5033 - val_accuracy: 0.7678\n",
            "Epoch 14/20\n",
            "1830/1830 [==============================] - 27s 15ms/step - loss: 0.5362 - accuracy: 0.8454 - val_loss: 1.5223 - val_accuracy: 0.7661\n",
            "Epoch 15/20\n",
            "1830/1830 [==============================] - 28s 15ms/step - loss: 0.5338 - accuracy: 0.8462 - val_loss: 1.4722 - val_accuracy: 0.7679\n",
            "Epoch 16/20\n",
            "1830/1830 [==============================] - 26s 14ms/step - loss: 0.5300 - accuracy: 0.8468 - val_loss: 1.3617 - val_accuracy: 0.7986\n",
            "Epoch 16: early stopping\n",
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\RNNen3_te_3_rmsprop_20_0.3_32_32\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\RNNen3_te_3_rmsprop_20_0.3_32_32\\assets\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 12820<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_004434-a13yjr8g\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_004434-a13yjr8g\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.84679</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>1.22984</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>loss</td><td>0.53004</td></tr><tr><td>val_accuracy</td><td>0.79864</td></tr><tr><td>val_loss</td><td>1.36174</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">fluent-sweep-6</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/a13yjr8g\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/a13yjr8g</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5i1knhps with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: adam\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">absurd-sweep-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/5i1knhps\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/5i1knhps</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_005207-5i1knhps</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 64),   17856       ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " gru_5 (GRU)                    [(None, None, 64),   25344       ['input_2[0][0]',                \n",
            "                                 (None, 64)]                      'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, None, 64),   17856       ['input_1[0][0]']                \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 64),  8256        ['gru[0][0]',                    \n",
            " r)                              (None, None, None)               'gru_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 128)    0           ['gru_5[0][0]',                  \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 64)     8256        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     4290        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 81,858\n",
            "Trainable params: 81,858\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "915/915 [==============================] - 45s 43ms/step - loss: 1.1867 - accuracy: 0.6898 - val_loss: 1.5432 - val_accuracy: 0.7061\n",
            "Epoch 2/20\n",
            "915/915 [==============================] - 37s 41ms/step - loss: 0.7304 - accuracy: 0.7915 - val_loss: 1.4884 - val_accuracy: 0.7609\n",
            "Epoch 3/20\n",
            "915/915 [==============================] - 46s 51ms/step - loss: 0.4758 - accuracy: 0.8616 - val_loss: 1.7370 - val_accuracy: 0.7377\n",
            "Epoch 4/20\n",
            "915/915 [==============================] - 47s 51ms/step - loss: 0.3994 - accuracy: 0.8822 - val_loss: 1.7076 - val_accuracy: 0.7606\n",
            "Epoch 5/20\n",
            "915/915 [==============================] - 42s 46ms/step - loss: 0.3639 - accuracy: 0.8920 - val_loss: 1.6349 - val_accuracy: 0.7836\n",
            "Epoch 6/20\n",
            "915/915 [==============================] - 44s 48ms/step - loss: 0.3371 - accuracy: 0.8992 - val_loss: 1.7228 - val_accuracy: 0.7731\n",
            "Epoch 7/20\n",
            "915/915 [==============================] - 45s 49ms/step - loss: 0.3225 - accuracy: 0.9032 - val_loss: 1.8299 - val_accuracy: 0.7649\n",
            "Epoch 8/20\n",
            "915/915 [==============================] - 37s 40ms/step - loss: 0.3082 - accuracy: 0.9072 - val_loss: 1.8705 - val_accuracy: 0.7598\n",
            "Epoch 9/20\n",
            "915/915 [==============================] - 36s 39ms/step - loss: 0.2982 - accuracy: 0.9098 - val_loss: 1.8199 - val_accuracy: 0.7782\n",
            "Epoch 10/20\n",
            "915/915 [==============================] - 36s 39ms/step - loss: 0.2896 - accuracy: 0.9122 - val_loss: 1.8980 - val_accuracy: 0.7712\n",
            "Epoch 10: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_3_adam_20_0.2_64_64\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_3_adam_20_0.2_64_64\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E72D973BE0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E74BCDA140> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E72918C730> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 17268<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_005207-5i1knhps\\logs\\debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_005207-5i1knhps\\logs\\debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td>0.91218</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>1.48842</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.28957</td></tr><tr><td>val_accuracy</td><td>0.7712</td></tr><tr><td>val_loss</td><td>1.89804</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">absurd-sweep-7</strong>: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/5i1knhps\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/5i1knhps</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bmq9s1q0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatentDim: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumDecoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumEncoders: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimiser: rmsprop\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.13.9 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.2<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">faithful-sweep-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/sweeps/q6wtpkdx</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/bmq9s1q0\" target=\"_blank\">https://wandb.ai/karanwxlia/Assignment-3_WithAttention/runs/bmq9s1q0</a><br/>\n",
              "                Run data is saved locally in <code>c:\\Users\\KARAN\\Desktop\\Assignmets for cs6910\\wandb\\run-20230129_005925-bmq9s1q0</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, 27)]   0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None, 66)]   0           []                               \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, None, 32),   5856        ['input_1[0][0]']                \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " gru_5 (GRU)                    [(None, None, 32),   9600        ['input_2[0][0]',                \n",
            "                                 (None, 32)]                      'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, None, 32),   5856        ['input_1[0][0]']                \n",
            "                                 (None, 32)]                                                      \n",
            "                                                                                                  \n",
            " attention_layer (AttentionLaye  ((None, None, 32),  2080        ['gru[0][0]',                    \n",
            " r)                              (None, None, None)               'gru_5[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 64)     0           ['gru_5[0][0]',                  \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 16)     1040        ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 66)     1122        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,554\n",
            "Trainable params: 25,554\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "915/915 [==============================] - 31s 27ms/step - loss: 1.3399 - accuracy: 0.6545 - val_loss: 1.4481 - val_accuracy: 0.6723\n",
            "Epoch 2/15\n",
            "915/915 [==============================] - 24s 26ms/step - loss: 1.0334 - accuracy: 0.7123 - val_loss: 1.6196 - val_accuracy: 0.7049\n",
            "Epoch 3/15\n",
            "915/915 [==============================] - 22s 24ms/step - loss: 0.9359 - accuracy: 0.7369 - val_loss: 1.6975 - val_accuracy: 0.7128\n",
            "Epoch 4/15\n",
            "915/915 [==============================] - 21s 23ms/step - loss: 0.8819 - accuracy: 0.7501 - val_loss: 1.6806 - val_accuracy: 0.7225\n",
            "Epoch 5/15\n",
            "915/915 [==============================] - 21s 23ms/step - loss: 0.8389 - accuracy: 0.7608 - val_loss: 1.8196 - val_accuracy: 0.7195\n",
            "Epoch 6/15\n",
            "915/915 [==============================] - 21s 23ms/step - loss: 0.8046 - accuracy: 0.7700 - val_loss: 1.7425 - val_accuracy: 0.7245\n",
            "Epoch 7/15\n",
            "915/915 [==============================] - 23s 26ms/step - loss: 0.7018 - accuracy: 0.8000 - val_loss: 1.5348 - val_accuracy: 0.7577\n",
            "Epoch 8/15\n",
            "915/915 [==============================] - 27s 30ms/step - loss: 0.5760 - accuracy: 0.8352 - val_loss: 1.7042 - val_accuracy: 0.7442\n",
            "Epoch 9/15\n",
            "915/915 [==============================] - 20s 22ms/step - loss: 0.5199 - accuracy: 0.8511 - val_loss: 1.5863 - val_accuracy: 0.7709\n",
            "Epoch 10/15\n",
            "915/915 [==============================] - 21s 23ms/step - loss: 0.4865 - accuracy: 0.8603 - val_loss: 1.8599 - val_accuracy: 0.7312\n",
            "Epoch 11/15\n",
            "915/915 [==============================] - 20s 22ms/step - loss: 0.4602 - accuracy: 0.8671 - val_loss: 1.7284 - val_accuracy: 0.7566\n",
            "Epoch 12/15\n",
            "915/915 [==============================] - 19s 21ms/step - loss: 0.4406 - accuracy: 0.8722 - val_loss: 1.6165 - val_accuracy: 0.7803\n",
            "Epoch 13/15\n",
            "915/915 [==============================] - 22s 24ms/step - loss: 0.4268 - accuracy: 0.8761 - val_loss: 1.7973 - val_accuracy: 0.7559\n",
            "Epoch 14/15\n",
            "915/915 [==============================] - 23s 25ms/step - loss: 0.4148 - accuracy: 0.8790 - val_loss: 1.9311 - val_accuracy: 0.7388\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_5_layer_call_fn, gru_cell_5_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_3_rmsprop_15_0.2_64_32\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./TrainedAttentionModels\\GRUen3_te_3_rmsprop_15_0.2_64_32\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E720B07EB0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E71FC399F0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E72EC044F0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 30660<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "  \n",
        "sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep without attention - 2\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \n",
        "        \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "        \n",
        "        \"latentDim\": {\"values\": [256, 128, 64, 32]},\n",
        "        \n",
        "        \"hidden\": {\"values\": [128, 64, 32, 16]},\n",
        "        \n",
        "        \"optimiser\": {\"values\": [\"rmsprop\", \"adam\"]},\n",
        "        \n",
        "        \"numEncoders\": {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"numDecoders\": {\"values\": [1, 2, 3]},\n",
        "        \n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "        \n",
        "        \"epochs\": {\"values\": [5,10,15, 20]},\n",
        "        \n",
        "        \"batch_size\": {\"values\": [32, 64]},\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Assignment-3_WithAttention\", entity=\"karanwxlia\")\n",
        "\n",
        "wandb.agent(sweep_id, train, count = 100)\n",
        "\n",
        "\n",
        "#train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAdZD_yk1ykO"
      },
      "source": [
        "Move the trained models to Google drive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment3-Seq2Seq-NeuralMachineTranslation-With-Attention.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7fdc5f3cce225da97ecbb62baa9d502a10bee8c564318ad754c1ff5e9f74492"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
