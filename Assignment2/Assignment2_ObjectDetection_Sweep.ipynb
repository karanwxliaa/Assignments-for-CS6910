{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zGZzbEmQ48A"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "gpu = tf.test.gpu_device_name()\n",
        "gpu\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrHj1bbxHjVi"
      },
      "outputs": [],
      "source": [
        "!pip install wandb==0.12.2\n",
        "\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip nature_12K.zip\n",
        "!rm nature_12K.zip\n",
        "\n",
        "!mv ./inaturalist_12K/val ./inaturalist_12K/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cykm-daIJXW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oqxnJgOIJO8"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "sys.path.append(\"/content/drive/MyDrive/CS6910/Assignment2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPECnwAsHjne"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2 as IRV2\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Conv2D, BatchNormalization, MaxPooling2D, Activation , GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential,  Model\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "class ObjectDetection():\n",
        "\n",
        "    def __init__(self, image_size, modelConfigDict, using_pretrained_model = False, base_model = \"IRV2\" ):\n",
        "        \n",
        "        self.no_hidden_cnn_layers= modelConfigDict[\"no_hidden_cnn_layers\"]\n",
        "        self.activation = modelConfigDict[\"activation\"]\n",
        "        self.batch_norm = modelConfigDict[\"batch_norm\"]\n",
        "        self.filter_dist = modelConfigDict[\"filter_dist\"]\n",
        "        self.filter_size = modelConfigDict[\"filter_size\"]\n",
        "        self.no_of_filters_base  = modelConfigDict[\"no_of_filters_base\"]\n",
        "        self.dropout_fraction = modelConfigDict[\"dropout_fraction\"]\n",
        "        self.pool_size = modelConfigDict[\"pool_size\"]\n",
        "        self.padding = modelConfigDict[\"padding\"]\n",
        "        self.dense_neurons = modelConfigDict[\"dense_neurons\"]\n",
        "        self.num_classes = modelConfigDict[\"num_classes\"]\n",
        "        self.optimizer = modelConfigDict[\"optimizer\"]\n",
        "        self.global_avg_pooling = modelConfigDict[\"global_avg_pooling\"]\n",
        "        self.batch_normalisation_location = modelConfigDict[\"batch_normalisation_location\"]\n",
        "        BASE_MODELS = {\n",
        "        \"IRV2\" : IRV2,\n",
        "        \"IV3\" : InceptionV3,\n",
        "        \"RN50\" : ResNet50,\n",
        "        \"XCPTN\" : Xception\n",
        "        }      \n",
        "        \n",
        "        if using_pretrained_model == True:\n",
        "            self.base_model = base_model\n",
        "\n",
        "            if self.base_model == \"RN50\":\n",
        "                self.IMG_HEIGHT = 224\n",
        "                self.IMG_WIDTH = 224\n",
        "\n",
        "            else:\n",
        "                self.IMG_HEIGHT = image_size[0]\n",
        "                self.IMG_WIDTH = image_size[1]        \n",
        "\n",
        "        self.IMG_HEIGHT = image_size[0]\n",
        "        self.IMG_WIDTH = image_size[1]        \n",
        "         \n",
        "        self.input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)\n",
        "\n",
        "    def build_cnnmodel_dense(self):\n",
        "\n",
        "        with tf.device('/device:GPU:0'):\n",
        "            tf.keras.backend.clear_session()\n",
        "            model = Sequential()\n",
        "            \n",
        "            #Input Layer\n",
        "            model.add(Conv2D(self.no_of_filters_base, self.filter_size ,kernel_initializer = \"he_uniform\",padding = self.padding,input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "            if self.batch_normalisation_location == \"Before\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            model.add(Activation(self.activation))\n",
        "            \n",
        "            #Performing Batch_normalisation\n",
        "            if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            \n",
        "            #Max pooling\n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "            for i in range(self.no_hidden_cnn_layers-1):\n",
        "            \n",
        "                ## Standard filter \n",
        "                if self.filter_dist == \"standard\":\n",
        "                    model.add(Conv2D(self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\",padding = self.padding))\n",
        "            \n",
        "                ## Double filter \n",
        "                elif self.filter_dist == \"double\":\n",
        "                    model.add(Conv2D(2**(i+1)*self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\",padding = self.padding))\n",
        "            \n",
        "                ## Half the filter size in each of the convolutional layers\n",
        "                elif self.filter_dist == \"half\":\n",
        "                    model.add(Conv2D(int(self.no_of_filters_base/2**(i+1)),self.filter_size, kernel_initializer = \"he_uniform\"))\n",
        "            \n",
        "                if self.batch_normalisation_location == \"Before\" and self.batch_norm: model.add(BatchNormalization())\n",
        "                model.add(Activation(self.activation))\n",
        "            \n",
        "                if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "                \n",
        "                model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "            \n",
        "            #Densely connected layers\n",
        "            if self.global_avg_pooling == True:\n",
        "                model.add(GlobalAveragePooling2D())\n",
        "            else:\n",
        "                model.add(Flatten())\n",
        "            model.add(Dense(self.dense_neurons, activation = 'sigmoid'))\n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "            model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "          \n",
        "            return model \n",
        "\n",
        "    def build_cnnmodel_conv(self):\n",
        "        with tf.device('/device:GPU:0'):\n",
        "            tf.keras.backend.clear_session()\n",
        "            model = Sequential()\n",
        "            \n",
        "            #First CNN layer connecting to input layer\n",
        "            model.add(Conv2D(self.no_of_filters_base, self.filter_size, padding = self.padding,kernel_initializer = \"he_uniform\", input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "            if self.batch_normalisation_location == \"Before\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            model.add(Activation(self.activation))\n",
        "            \n",
        "            #batch_normalisation\n",
        "            if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            #max pooling\n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "            for i in range(self.no_hidden_cnn_layers-1):\n",
        "                #i+2th Convolutional Layer\n",
        "            \n",
        "                ## Standard filter distribution - same number of filters in all Convolutional layers\n",
        "                if self.filter_dist == \"standard\":\n",
        "                    model.add(Conv2D(self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\",padding = self.padding))\n",
        "            \n",
        "                ## Double filter distribution - double number of filters in each Convolutional layers\n",
        "                elif self.filter_dist == \"double\":\n",
        "                    model.add(Conv2D(2**(i+1)*self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\", padding = self.padding))\n",
        "            \n",
        "                ## Halve the filter size in each successive convolutional layers\n",
        "                elif self.filter_dist == \"half\":\n",
        "                    model.add(Conv2D(int(self.no_of_filters_base/2**(i+1)), self.filter_size,kernel_initializer = \"he_uniform\", padding = self.padding))\n",
        "            \n",
        "                if self.batch_normalisation_location == \"Before\" and self.batch_norm: model.add(BatchNormalization())\n",
        "                model.add(Activation(self.activation))\n",
        "            \n",
        "                if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            \n",
        "                model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "                if self.dropout_fraction != None:\n",
        "                    model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "            \n",
        "            #Final densely connected layers\n",
        "            if self.global_avg_pooling == True:\n",
        "                model.add(GlobalAveragePooling2D())\n",
        "            else:\n",
        "                model.add(Flatten())\n",
        "\n",
        "            model.add(Dense(self.dense_neurons, activation = 'sigmoid'))\n",
        "            model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "\n",
        "            return model      \n",
        "        \n",
        "    def build_cnnmodel_all(self):\n",
        "\n",
        "        with tf.device('/device:GPU:0'):    \n",
        "            tf.keras.backend.clear_session()\n",
        "            model = Sequential()\n",
        "            \n",
        "            #First CNN layer\n",
        "            model.add(Conv2D(self.no_of_filters_base, self.filter_size, padding = self.padding,kernel_initializer = \"he_uniform\", input_shape = (self.IMG_HEIGHT, self.IMG_WIDTH, 3)))\n",
        "            model.add(Activation(self.activation))\n",
        "            \n",
        "            #Batch_normalisation\n",
        "            if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            \n",
        "            #Max pooling\n",
        "            model.add(MaxPooling2D(pool_size=self.pool_size))  \n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "\n",
        "            for i in range(self.no_hidden_cnn_layers-1):\n",
        "            \n",
        "                ## Standard filter distribution\n",
        "                if self.filter_dist == \"standard\":\n",
        "                    model.add(Conv2D(self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\", padding = self.padding))\n",
        "            \n",
        "                ## Double filter distribution\n",
        "                elif self.filter_dist == \"double\":\n",
        "                    model.add(Conv2D(2**(i+1)*self.no_of_filters_base, self.filter_size,kernel_initializer = \"he_uniform\",padding = self.padding))\n",
        "            \n",
        "                ## Halve the filter size in each successive convolutional layers\n",
        "                elif self.filter_dist == \"half\":\n",
        "                    model.add(Conv2D(int(self.no_of_filters_base/2**(i+1)), self.filter_size,kernel_initializer = \"he_uniform\", padding = self.padding))\n",
        "            \n",
        "                model.add(Activation(self.activation))\n",
        "            \n",
        "                if self.batch_normalisation_location == \"After\" and self.batch_norm: model.add(BatchNormalization())\n",
        "            \n",
        "                model.add(MaxPooling2D(pool_size=self.pool_size))\n",
        "                if self.dropout_fraction != None:\n",
        "                    model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "            \n",
        "            #Densely connected layers\n",
        "            if self.global_avg_pooling == True:\n",
        "                model.add(GlobalAveragePooling2D())\n",
        "            else:\n",
        "                model.add(Flatten())\n",
        "\n",
        "            model.add(Dense(self.dense_neurons, activation = 'sigmoid'))\n",
        "            if self.dropout_fraction != None:\n",
        "                model.add(tf.keras.layers.Dropout(self.dropout_fraction))\n",
        "            model.add(Dense(self.num_classes, activation = 'softmax'))\n",
        "            \n",
        "            return model      \n",
        "      \n",
        "    \n",
        "                 \n",
        "        \n",
        "    def load_pretrained_model(self):\n",
        "        \n",
        "        base_model = BASE_MODELS[self.base_model_name]\n",
        "        base = base_model(weights='imagenet', include_top=False)\n",
        "        x = base.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(self.dense_neurons, activation='relu')(x)\n",
        "        guess = Dense(self.num_classes, activation='softmax')(x)\n",
        "        model = Model(inputs=base.input, outputs=guess)\n",
        "\n",
        "        # freeze the base layers\n",
        "        for l in base.layers:\n",
        "            l.trainable = False\n",
        "\n",
        "        return model\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og5Ds0aQIHWI"
      },
      "outputs": [],
      "source": [
        "#Preprocessing the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "IMG_SIZE = (128,128)\n",
        "\n",
        "'''\n",
        "#sweep config\n",
        "sweep_config = {\n",
        "  \"name\": \"Bayesian Sweep\",\n",
        "  \"method\": \"bayes\",\n",
        "  \"metric\":{\n",
        "  \"name\": \"val_accuracy\",\n",
        "  \"goal\": \"maximize\"\n",
        "  },\n",
        "  'early_terminate': {\n",
        "        'type':'hyperband',\n",
        "        'min_iter': [3],\n",
        "        's': [2]\n",
        "  },\n",
        "  \"parameters\": {\n",
        "        \n",
        "        \"activation\":{\n",
        "            \"values\": [\"relu\", \"elu\", \"selu\"]\n",
        "        },\n",
        "        \"filter_size\": {\n",
        "            \"values\": [(2,2), (3,3), (4,4)]\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [32, 64]\n",
        "        },\n",
        "        \"padding\": {\n",
        "            \"values\": [\"same\",\"valid\"]\n",
        "        },\n",
        "        \"data_augmentation\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\": [\"sgd\", \"adam\", \"rmsprop\", \"nadam\"]\n",
        "        },\n",
        "        \"batch_normalization\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "        \"batch_normalisation_location\": {\n",
        "            \"values\": [\"Before\", \"After\"]\n",
        "        },\n",
        "        \"number_of_filters_base\": {\n",
        "            \"values\": [32, 64]\n",
        "        },\n",
        "        \"dense_neurons\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        },   \n",
        "        \"dropout_location\": {\n",
        "            \"values\": [\"conv\",\"dense\",\"all\"]\n",
        "        },\n",
        "        \"dropout_fraction\": {\n",
        "            \"values\": [None, 0.2,0.3]\n",
        "        },  \n",
        "        \"global_average_pooling\": {\n",
        "            \"values\": [False,True]\n",
        "        },        \n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config,project='Assignment-2', entity='karanwxlia')\n",
        "'''\n",
        "\n",
        "\n",
        "#train function\n",
        "def train():\n",
        "\n",
        "        \n",
        "    config_defaults = dict(\n",
        "            num_hidden_cnn_layers = 5 ,\n",
        "            activation = 'relu',\n",
        "            batch_normalization = True,\n",
        "            batch_normalisation_location = \"After\",\n",
        "            filter_distribution = \"double\" ,\n",
        "            filter_size = (3,3),\n",
        "            number_of_filters_base  = 32,\n",
        "            dropout_fraction = None,\n",
        "            dropout_location = \"dense\",\n",
        "            pool_size = (2,2),\n",
        "            padding = 'same',\n",
        "            dense_neurons = 128,\n",
        "            num_classes = 10,\n",
        "            optimizer = 'adam',\n",
        "            epochs = 5,\n",
        "            batch_size = 32, \n",
        "            data_augmentation = False,\n",
        "            global_average_pooling = True,\n",
        "            img_size = IMG_SIZE\n",
        "        ) \n",
        "\n",
        "\n",
        "\n",
        "    wandb.init(project = 'Assignment-2', config = config_defaults,entity='karanwxlia')\n",
        "    CONFIG = wandb.config\n",
        "\n",
        "    #RUN name for wandb\n",
        "    wandb.run.name = \"OBJDET_\" + str(CONFIG.num_hidden_cnn_layers) + \"_dn_\" + str(CONFIG.dense_neurons) + \"_opt_\" + CONFIG.optimizer + \"_dro_\" + str(CONFIG.dropout_fraction) + \"_bs_\"+str(CONFIG.batch_size) + \"_fd_\" + CONFIG.filter_distribution + \"_bnl_\" + CONFIG.batch_normalisation_location + \"_dpl_\" + CONFIG.dropout_location\n",
        "    data_augmentation = CONFIG.data_augmentation\n",
        "    BATCH_SIZE = CONFIG.batch_size\n",
        "\n",
        "    if data_augmentation == True:\n",
        "\n",
        "    #Better Alternative\n",
        "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "                rescale=1./255,\n",
        "                val_split = 0.1,\n",
        "                shear_range=0.2,\n",
        "                zoom_range=0.2,\n",
        "                featurewise_center=False,  \n",
        "                samplewise_center=False,  \n",
        "                featurewise_std_normalization=False,\n",
        "                samplewise_std_normalization=False, \n",
        "                zca_whitening=False,  \n",
        "                rotation_range=15,  \n",
        "                width_shift_range=0.1,\n",
        "                height_shift_range=0.1,\n",
        "                horizontal_flip=True,  \n",
        "                vertical_flip=False\n",
        "                )\n",
        "    else:\n",
        "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,val_split = 0.1)\n",
        "\n",
        "    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        './inaturalist_12K/train',\n",
        "        subset='training',\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical',\n",
        "        shuffle = True,\n",
        "        seed = 123)\n",
        "        \n",
        "    validation_generator = train_datagen.flow_from_directory(\n",
        "            './inaturalist_12K/train',\n",
        "            target_size=IMG_SIZE,\n",
        "            subset = 'validation',\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='categorical',\n",
        "            shuffle = True,\n",
        "            seed = 123)\n",
        "\n",
        "\n",
        "            \n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "            './inaturalist_12K/test',\n",
        "            target_size=IMG_SIZE,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            class_mode='categorical',\n",
        "            shuffle = True,\n",
        "            seed = 123)\n",
        "\n",
        "\n",
        "\n",
        "    with tf.device('/device:GPU:0'):        \n",
        "        objDetn = ObjectDetection(CONFIG.img_size, CONFIG )\n",
        "        if CONFIG.dropout_location == \"all\":\n",
        "            model = objDetn.build_cnnmodel_all()\n",
        "        elif CONFIG.dropout_location == \"conv\":\n",
        "            model = objDetn.build_cnnmodel_conv()\n",
        "        elif CONFIG.dropout_location == \"dense\":\n",
        "            model = objDetn.build_cnnmodel_dense()\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "\n",
        "\n",
        "        model.compile(\n",
        "        optimizer=CONFIG.optimizer,  \n",
        "        # Loss function \n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy'],\n",
        "        )\n",
        "      \n",
        "        history = model.fit(\n",
        "                        train_generator,\n",
        "                        steps_per_epoch = train_generator.samples // CONFIG.batch_size,\n",
        "                        validation_data = validation_generator, \n",
        "                        validation_steps = validation_generator.samples // CONFIG.batch_size,\n",
        "                        epochs = CONFIG.epochs, \n",
        "                        callbacks=[WandbCallback()]\n",
        "                        )\n",
        "\n",
        "        model.save('./TrainedModel/'+wandb.run.name)\n",
        "        wandb.finish()\n",
        "        return model, history\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56JrOEMmWplD"
      },
      "outputs": [],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJqO8m9MLj7c"
      },
      "outputs": [],
      "source": [
        "#wandb.agent(sweep_id, train, count = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfMqdTMFz0b1"
      },
      "outputs": [],
      "source": [
        "!cp -rf /content/TrainedModel/OBJDET_5_dn_128_opt_nadam_dro_None_bs_32_fd_double_bnl_After_dpl_all  /content/drive/MyDrive/CS6910/Assignment2/Best_trained_Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8JCbnQjQEa-"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7fdc5f3cce225da97ecbb62baa9d502a10bee8c564318ad754c1ff5e9f74492"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}